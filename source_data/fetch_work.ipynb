{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 6627it [00:01, 2058.15it/s]                \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "def get_place_work_relationships(place_id, headers, relationship_types=None):\n",
    "    \"\"\"\n",
    "    Fetch all place-work relationships for a given place ID.\n",
    "\n",
    "    Args:\n",
    "        place_id (str): The MusicBrainz ID of the place.\n",
    "        headers (dict): Headers to be used in the API request.\n",
    "        relationship_types (list, optional): List of relationship types to filter by.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of filtered relationships for the given place ID.\n",
    "    \"\"\"\n",
    "    if not place_id or len(place_id) != 36:  # Validate UUID format\n",
    "        print(f\"Invalid place ID: {place_id}\")\n",
    "        return []\n",
    "\n",
    "    BASE_URL = \"https://musicbrainz.org/ws/2\"\n",
    "    endpoint = f\"{BASE_URL}/place/{place_id}\"\n",
    "    params = {\"inc\": \"work-rels\", \"fmt\": \"json\"}  # Changed to 'work-rels'\n",
    "\n",
    "    try:\n",
    "        response = requests.get(endpoint, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if not data or \"relations\" not in data:\n",
    "            print(f\"No relations found for place ID: {place_id}\")\n",
    "            return []\n",
    "\n",
    "        # Fetch all relationships\n",
    "        relationships = data.get(\"relations\", [])\n",
    "\n",
    "        # Filter relationships if relationship_types is provided\n",
    "        if relationship_types:\n",
    "            relationships = [\n",
    "                rel for rel in relationships if rel.get(\"type\") in relationship_types\n",
    "            ]\n",
    "\n",
    "        # Return all matching relationships\n",
    "        return relationships if relationships else []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching place-work relationships for {place_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "# 1. Read your list of places from a CSV\n",
    "places_file = 'places.csv'\n",
    "places_df = pd.read_csv(places_file)\n",
    "place_ids = places_df['id'].astype(str).tolist()\n",
    "\n",
    "# 2. Define headers as a dictionary\n",
    "headers = {\n",
    "    'User-Agent': 'jihbr@umich.edu'  \n",
    "}\n",
    "\n",
    "# 3. Define the relationship types to include (Place-Work relationship types)\n",
    "relationship_types = [\n",
    "    \"premiere\",\n",
    "    \"written at\",\n",
    "    \"composed at\",\n",
    "    \"lyrics written at\",\n",
    "    \"libretto written at\",\n",
    "    \"revised at\",\n",
    "    \"translated at\",\n",
    "    \"arranged at\",\n",
    "    \"commissioned\",\n",
    "    \"dedication\"\n",
    "]\n",
    "\n",
    "# Initialize variables for checkpointing\n",
    "BATCH_SIZE = 20\n",
    "checkpoint_file = 'checkpoint_place_work.parquet'\n",
    "output_file = 'place_work_relationships.parquet'\n",
    "output_data = []\n",
    "count_since_checkpoint = 0\n",
    "\n",
    "# Load checkpoint if exists\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint_df = pd.read_parquet(checkpoint_file)\n",
    "    processed_place_ids = set(checkpoint_df['place_id'].tolist())\n",
    "    output_data = checkpoint_df.to_dict('records')\n",
    "else:\n",
    "    processed_place_ids = set()\n",
    "\n",
    "# Process the place IDs in batches\n",
    "for i in tqdm(range(0, len(place_ids), BATCH_SIZE), desc=\"Processing batches\", initial=len(processed_place_ids) // BATCH_SIZE, total=len(place_ids) // BATCH_SIZE):\n",
    "    batch_place_ids = place_ids[i:i + BATCH_SIZE]\n",
    "    batch_output_data = []\n",
    "\n",
    "    for place_id in batch_place_ids:\n",
    "        if place_id in processed_place_ids:\n",
    "            continue\n",
    "\n",
    "        relationships = get_place_work_relationships(place_id, headers, relationship_types)\n",
    "        batch_output_data.append({'place_id': place_id, 'relationships': relationships})\n",
    "        processed_place_ids.add(place_id)\n",
    "\n",
    "    # Append batch data to output data\n",
    "    output_data.extend(batch_output_data)\n",
    "    count_since_checkpoint += len(batch_output_data)\n",
    "\n",
    "    # Save checkpoint if batch size is reached\n",
    "    if count_since_checkpoint >= BATCH_SIZE:\n",
    "        temp_df = pd.DataFrame(output_data)\n",
    "        \n",
    "        # Convert the 'relationships' column to JSON strings to make it compatible with Parquet\n",
    "        if 'relationships' in temp_df.columns:\n",
    "            temp_df['relationships'] = temp_df['relationships'].apply(json.dumps)\n",
    "        \n",
    "        temp_df.to_parquet(checkpoint_file, compression='snappy')\n",
    "        count_since_checkpoint = 0\n",
    "\n",
    "# Save final output\n",
    "final_output_df = pd.DataFrame(output_data)\n",
    "\n",
    "# Convert the 'relationships' column to JSON strings for the final save\n",
    "if 'relationships' in final_output_df.columns:\n",
    "    final_output_df['relationships'] = final_output_df['relationships'].apply(json.dumps)\n",
    "\n",
    "final_output_df.to_parquet(output_file, compression='snappy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
